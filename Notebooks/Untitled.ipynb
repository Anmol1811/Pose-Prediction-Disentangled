{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civic-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    " \n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms, utils\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "devoted-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, dtype):\n",
    "        \n",
    "        self.args = args\n",
    "        self.dtype = dtype\n",
    "        print(\"Loading\",self.dtype)\n",
    "        \n",
    "#         sequence_centric = pd.read_csv(\"sequences_16_overlap_4_thres0_\"+self.dtype+\".csv\")\n",
    "        sequence_centric = pd.read_csv(\"sequences_4_\"+self.dtype+\".csv\")\n",
    "\n",
    "        df = sequence_centric.copy()      \n",
    "        for v in list(df.columns.values):\n",
    "            print(v+' loaded')\n",
    "            try:\n",
    "                df.loc[:,v] = df.loc[:, v].apply(lambda x: literal_eval(x))\n",
    "            except:\n",
    "                continue\n",
    "        sequence_centric[df.columns] = df[df.columns]\n",
    "        self.data = sequence_centric.copy().reset_index(drop=True)\n",
    "    \n",
    "        print('*'*30)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        seq = self.data.iloc[index]\n",
    "        outputs = []\n",
    "\n",
    "        observed = torch.tensor(np.array(seq.Pose))\n",
    "        future = torch.tensor(np.array(seq.Future_Pose))\n",
    "\n",
    "        obs = torch.tensor([seq.Pose[i] for i in range(0,self.args.input,self.args.skip)])\n",
    "        obs_speed = (obs[1:] - obs[:-1])\n",
    "    \n",
    "        outputs.append(obs_speed)\n",
    "        \n",
    "        \n",
    "        true = torch.tensor([seq.Future_Pose[i] for i in range(0,self.args.output,self.args.skip)])\n",
    "        true_speed = torch.cat(((true[0]-obs[-1]).unsqueeze(0), true[1:]-true[:-1]))\n",
    "\n",
    "\n",
    "        outputs.append(true_speed)\n",
    "        outputs.append(obs)\n",
    "        outputs.append(true)\n",
    "        \n",
    "        return tuple(outputs)    \n",
    "    \n",
    "    \n",
    "def data_loader(args,data):\n",
    "    dataset = myDataset(args,data)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=args.batch_size, shuffle=args.loader_shuffle,\n",
    "        pin_memory=args.pin_memory)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "\n",
    "#Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "major-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=4\n",
    "batch_size=2\n",
    "def ADE_c(pred, true):\n",
    "#     print(pred[0,0])\n",
    "    pred = torch.reshape(pred, (batch_size,seq_len,25,2))\n",
    "    true = torch.reshape(true, (batch_size,seq_len,25,2))\n",
    "    \n",
    "    t=torch.sqrt((pred[:,:,:,0]-true[:,:,:,0])**2+(pred[:,:,:,1]-true[:,:,:,1])**2)\n",
    "    print(t.shape)\n",
    "#     print(pred[0,0])\n",
    "#     print(pred.shape,true.shape)\n",
    "#     displacement = torch.sqrt(torch.sum((pred-true])**2,dim=0))\n",
    "#     ade = torch.mean(displacement)\n",
    "    \n",
    "#     return ade\n",
    "\n",
    "\n",
    "def FDE_c(pred, true):\n",
    "    displacement = torch.sqrt(torch.sum((pred[:,-1,:]-true[:,-1,:])**2,dim=0))\n",
    "    fde = torch.mean(displacement)\n",
    "    \n",
    "    return fde\n",
    "\n",
    "def speed2pos(preds, obs_p):\n",
    "    pred_pos = torch.zeros(preds.shape[0], preds.shape[1], 50)\n",
    "    current = obs_p[:,-1,:]\n",
    "    \n",
    "    for i in range(preds.shape[1]):\n",
    "        pred_pos[:,i,:] = current + preds[:,i,:]\n",
    "        current = pred_pos[:,i,:]\n",
    "        \n",
    "    for i in range(50):\n",
    "        pred_pos[:,:,i] = torch.min(pred_pos[:,:,i], 1920*torch.ones(pred_pos.shape[0], pred_pos.shape[1]))#, device='cuda'))\n",
    "    #     pred_pos[:,:,1] = torch.min(pred_pos[:,:,1], 1080*torch.ones(pred_pos.shape[0], pred_pos.shape[1]))#, device='cuda'))\n",
    "        pred_pos[:,:,i] = torch.max(pred_pos[:,:,i], torch.zeros(pred_pos.shape[0], pred_pos.shape[1]))#, device='cuda'))\n",
    "    #     pred_pos[:,:,1] = torch.max(pred_pos[:,:,1], torch.zeros(pred_pos.shape[0], pred_pos.shape[1]))#, device='cuda'))\n",
    "        \n",
    "    return pred_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "compatible-wayne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val\n",
      "Pose loaded\n",
      "Future_Pose loaded\n",
      "******************************\n",
      "tensor([[[1139.,  677., 1142.,  678., 1142.,  680., 1143.,  692., 1145.,  701.,\n",
      "          1143.,  677., 1148.,  695., 1145.,  704., 1142.,  707., 1142.,  707.,\n",
      "          1140.,  725., 1139.,  751., 1142.,  707., 1142.,  727., 1140.,  751.,\n",
      "          1140.,  674., 1140.,  672., 1140.,  672., 1142.,  672., 1143.,  754.,\n",
      "          1142.,  751., 1140.,  754., 1140.,  754., 1137.,  754., 1137.,  754.],\n",
      "         [1139.,  671., 1142.,  672., 1143.,  672., 1148.,  692., 1145.,  698.,\n",
      "          1140.,  672., 1140.,  692., 1142.,  698., 1140.,  704., 1142.,  704.,\n",
      "          1140.,  725., 1140.,  745., 1140.,  704., 1140.,  725., 1140.,  745.,\n",
      "          1142.,  669., 1139.,  669., 1142.,  663., 1140.,  669., 1143.,  751.,\n",
      "          1143.,  751., 1142.,  748., 1142.,  748., 1142.,  751., 1140.,  745.],\n",
      "         [1140.,  669., 1142.,  672., 1142.,  672., 1142.,  692., 1140.,  695.,\n",
      "          1142.,  672., 1143.,  692., 1145.,  698., 1140.,  701., 1140.,  701.,\n",
      "          1140.,  722., 1140.,  742., 1140.,  701., 1140.,  722., 1140.,  745.,\n",
      "          1142.,  668., 1140.,  666., 1142.,  666., 1142.,  668., 1143.,  748.,\n",
      "          1145.,  748., 1140.,  745., 1140.,  748., 1140.,  751., 1140.,  745.],\n",
      "         [1140.,  666., 1140.,  672., 1140.,  672., 1137.,  692., 1137.,  701.,\n",
      "          1142.,  672., 1145.,  692., 1148.,  704., 1140.,  710., 1140.,  710.,\n",
      "          1139.,  730., 1137.,  751., 1140.,  710., 1140.,  733., 1140.,  751.,\n",
      "          1140.,  666., 1140.,  663., 1140.,  663., 1142.,  666., 1142.,  760.,\n",
      "          1142.,  760., 1140.,  754., 1137.,  757., 1137.,  757., 1137.,  754.]],\n",
      "\n",
      "        [[ 995.,  692.,  975.,  713.,  975.,  713.,  975.,  742.,  995.,  763.,\n",
      "           978.,  710.,  995.,  736., 1001.,  751.,  975.,  769.,  975.,  769.,\n",
      "           995.,  813.,  989.,  866.,  975.,  769.,  984.,  813.,  975.,  857.,\n",
      "           989.,  689.,  987.,  689.,  978.,  689.,  975.,  692.,  981.,  863.,\n",
      "           981.,  860.,  963.,  860., 1007.,  875., 1001.,  880.,  981.,  875.],\n",
      "         [ 992.,  689.,  978.,  710.,  972.,  713.,  969.,  739.,  989.,  757.,\n",
      "           981.,  707.,  998.,  736., 1004.,  745.,  978.,  769.,  978.,  769.,\n",
      "           992.,  813.,  984.,  872.,  981.,  769.,  986.,  816.,  975.,  863.,\n",
      "           987.,  686.,  989.,  686.,  978.,  689.,  978.,  686.,  992.,  878.,\n",
      "           995.,  878.,  966.,  866., 1004.,  880.,  998.,  881.,  978.,  878.],\n",
      "         [ 995.,  692.,  978.,  713.,  975.,  716.,  972.,  742.,  986.,  760.,\n",
      "           986.,  713.,  998.,  739., 1004.,  748.,  981.,  772.,  978.,  772.,\n",
      "           984.,  819.,  975.,  863.,  987.,  772.,  995.,  816.,  978.,  860.,\n",
      "           992.,  689.,  992.,  689.,  978.,  692.,  986.,  689.,  995.,  872.,\n",
      "           995.,  866.,  975.,  860.,  998.,  878.,  987.,  880.,  975.,  872.],\n",
      "         [1004.,  692.,  989.,  710.,  978.,  707.,  975.,  739.,  981.,  763.,\n",
      "           998.,  707.,  998.,  736., 1007.,  751.,  984.,  769.,  978.,  769.,\n",
      "           986.,  816.,  975.,  863.,  992.,  769.,  998.,  813.,  978.,  857.,\n",
      "          1001.,  689., 1001.,  692.,  995.,  689.,  998.,  686.,  998.,  875.,\n",
      "           998.,  866.,  975.,  857.,  995.,  880.,  984.,  880.,  972.,  872.]]])\n",
      "tensor([[[1139.,  677., 1142.,  678., 1142.,  680., 1143.,  692., 1145.,  701.,\n",
      "          1143.,  677., 1148.,  695., 1145.,  704., 1142.,  707., 1142.,  707.,\n",
      "          1140.,  725., 1139.,  751., 1142.,  707., 1142.,  727., 1140.,  751.,\n",
      "          1140.,  674., 1140.,  672., 1140.,  672., 1142.,  672., 1143.,  754.,\n",
      "          1142.,  751., 1140.,  754., 1140.,  754., 1137.,  754., 1137.,  754.],\n",
      "         [1139.,  671., 1142.,  672., 1143.,  672., 1148.,  692., 1145.,  698.,\n",
      "          1140.,  672., 1140.,  692., 1142.,  698., 1140.,  704., 1142.,  704.,\n",
      "          1140.,  725., 1140.,  745., 1140.,  704., 1140.,  725., 1140.,  745.,\n",
      "          1142.,  669., 1139.,  669., 1142.,  663., 1140.,  669., 1143.,  751.,\n",
      "          1143.,  751., 1142.,  748., 1142.,  748., 1142.,  751., 1140.,  745.],\n",
      "         [1140.,  669., 1142.,  672., 1142.,  672., 1142.,  692., 1140.,  695.,\n",
      "          1142.,  672., 1143.,  692., 1145.,  698., 1140.,  701., 1140.,  701.,\n",
      "          1140.,  722., 1140.,  742., 1140.,  701., 1140.,  722., 1140.,  745.,\n",
      "          1142.,  668., 1140.,  666., 1142.,  666., 1142.,  668., 1143.,  748.,\n",
      "          1145.,  748., 1140.,  745., 1140.,  748., 1140.,  751., 1140.,  745.],\n",
      "         [1140.,  666., 1140.,  672., 1140.,  672., 1137.,  692., 1137.,  701.,\n",
      "          1142.,  672., 1145.,  692., 1148.,  704., 1140.,  710., 1140.,  710.,\n",
      "          1139.,  730., 1137.,  751., 1140.,  710., 1140.,  733., 1140.,  751.,\n",
      "          1140.,  666., 1140.,  663., 1140.,  663., 1142.,  666., 1142.,  760.,\n",
      "          1142.,  760., 1140.,  754., 1137.,  757., 1137.,  757., 1137.,  754.]],\n",
      "\n",
      "        [[ 995.,  692.,  975.,  713.,  975.,  713.,  975.,  742.,  995.,  763.,\n",
      "           978.,  710.,  995.,  736., 1001.,  751.,  975.,  769.,  975.,  769.,\n",
      "           995.,  813.,  989.,  866.,  975.,  769.,  984.,  813.,  975.,  857.,\n",
      "           989.,  689.,  987.,  689.,  978.,  689.,  975.,  692.,  981.,  863.,\n",
      "           981.,  860.,  963.,  860., 1007.,  875., 1001.,  880.,  981.,  875.],\n",
      "         [ 992.,  689.,  978.,  710.,  972.,  713.,  969.,  739.,  989.,  757.,\n",
      "           981.,  707.,  998.,  736., 1004.,  745.,  978.,  769.,  978.,  769.,\n",
      "           992.,  813.,  984.,  872.,  981.,  769.,  986.,  816.,  975.,  863.,\n",
      "           987.,  686.,  989.,  686.,  978.,  689.,  978.,  686.,  992.,  878.,\n",
      "           995.,  878.,  966.,  866., 1004.,  880.,  998.,  881.,  978.,  878.],\n",
      "         [ 995.,  692.,  978.,  713.,  975.,  716.,  972.,  742.,  986.,  760.,\n",
      "           986.,  713.,  998.,  739., 1004.,  748.,  981.,  772.,  978.,  772.,\n",
      "           984.,  819.,  975.,  863.,  987.,  772.,  995.,  816.,  978.,  860.,\n",
      "           992.,  689.,  992.,  689.,  978.,  692.,  986.,  689.,  995.,  872.,\n",
      "           995.,  866.,  975.,  860.,  998.,  878.,  987.,  880.,  975.,  872.],\n",
      "         [1004.,  692.,  989.,  710.,  978.,  707.,  975.,  739.,  981.,  763.,\n",
      "           998.,  707.,  998.,  736., 1007.,  751.,  984.,  769.,  978.,  769.,\n",
      "           986.,  816.,  975.,  863.,  992.,  769.,  998.,  813.,  978.,  857.,\n",
      "          1001.,  689., 1001.,  692.,  995.,  689.,  998.,  686.,  998.,  875.,\n",
      "           998.,  866.,  975.,  857.,  995.,  880.,  984.,  880.,  972.,  872.]]])\n",
      "torch.Size([2, 4, 25])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b63b0e549c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mpreds_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspeed2pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobs_pose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mADE_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_pose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFDE_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_pose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        self.loader_workers = 1\n",
    "        self.loader_shuffle = False\n",
    "        self.device         = 'cuda'\n",
    "        self.batch_size     = 2\n",
    "        self.n_epochs       = 200\n",
    "        self.hidden_size    = 6400\n",
    "        self.hardtanh_limit = 100\n",
    "        self.input  = 4\n",
    "        self.output = 4\n",
    "        self.pin_memory= False\n",
    "        self.stride = 4\n",
    "        self.skip   = 1\n",
    "        self.task   = 'pose'\n",
    "        self.use_scenes = False       \n",
    "        self.lr = 0.001\n",
    "        \n",
    "args = args()\n",
    "val_loader=data_loader(args,\"val\" )\n",
    "for idx, (obs_s, target_s, obs_pose, target_pose) in enumerate(val_loader):\n",
    "#     print(obs_s)\n",
    "#     print(target_s)\n",
    "#     print(obs_pose)\n",
    "    print(target_pose)\n",
    "    \n",
    "    preds_p=speed2pos(target_s,obs_pose)\n",
    "    print(preds_p)\n",
    "    print(float(ADE_c(preds_p, target_pose)))\n",
    "    print(float(FDE_c(preds_p, target_pose)))\n",
    "            \n",
    "#         for i in range(1,16):\n",
    "#             preds_p = speed_preds[:,i,:]+preds_p[:,-1:,:]\n",
    "#             ade_train += float(ADE_c(preds_p, target_pose[:,i:i+1,:]))\n",
    "#             fde_train += float(FDE_c(preds_p, target_pose[:,i:i+1,:]))\n",
    "            \n",
    "        \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-toolbox",
   "metadata": {},
   "source": [
    "# PoseLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "friendly-manitoba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train\n",
      "Pose loaded\n",
      "Future_Pose loaded\n",
      "******************************\n",
      "Loading val\n",
      "Pose loaded\n",
      "Future_Pose loaded\n",
      "******************************\n",
      "====================================================================================================\n",
      "Training ...\n",
      "e: 0 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 49.6210 | ade_val: 45.8807 | fde_train: 99.0719 | fde_val: 84.3724\n",
      "e: 1 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 36.7938 | ade_val: 43.1043 | fde_train: 69.9444 | fde_val: 77.9061\n",
      "e: 2 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 46.2328 | ade_val: 52.1490 | fde_train: 93.4079 | fde_val: 105.9055\n",
      "e: 3 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 41.7121 | ade_val: 54.3765 | fde_train: 85.0027 | fde_val: 115.4621\n",
      "e: 4 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 46.6465 | ade_val: 53.0824 | fde_train: 102.7775 | fde_val: 119.0059\n",
      "e: 5 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 42.2438 | ade_val: 47.8939 | fde_train: 96.4135 | fde_val: 106.1895\n",
      "e: 6 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 38.0078 | ade_val: 41.2325 | fde_train: 81.5716 | fde_val: 89.3351\n",
      "e: 7 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 32.1420 | ade_val: 38.4411 | fde_train: 68.8189 | fde_val: 76.6427\n",
      "e: 8 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 29.3761 | ade_val: 35.0838 | fde_train: 53.5232 | fde_val: 67.5324\n",
      "e: 9 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 26.9436 | ade_val: 32.7493 | fde_train: 47.0980 | fde_val: 65.3995\n",
      "e: 10 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 25.4706 | ade_val: 31.7085 | fde_train: 45.8644 | fde_val: 62.6844\n",
      "e: 11 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 24.3886 | ade_val: 31.2153 | fde_train: 41.8581 | fde_val: 59.2030\n",
      "e: 12 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 23.0008 | ade_val: 29.2058 | fde_train: 38.7557 | fde_val: 57.0911\n",
      "e: 13 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 22.0212 | ade_val: 27.1431 | fde_train: 38.5771 | fde_val: 52.7801\n",
      "e: 14 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 21.0800 | ade_val: 28.8010 | fde_train: 36.6187 | fde_val: 57.7523\n",
      "e: 15 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 21.3046 | ade_val: 27.2799 | fde_train: 36.8405 | fde_val: 55.3618\n",
      "e: 16 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 20.5851 | ade_val: 26.1552 | fde_train: 37.0343 | fde_val: 52.8431\n",
      "e: 17 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 19.8761 | ade_val: 25.3357 | fde_train: 35.2737 | fde_val: 49.7281\n",
      "e: 18 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 18.7347 | ade_val: 23.6721 | fde_train: 32.1566 | fde_val: 47.1782\n",
      "e: 19 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 18.2999 | ade_val: 23.3092 | fde_train: 32.1314 | fde_val: 43.6563\n",
      "e: 20 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 17.8976 | ade_val: 22.2557 | fde_train: 30.0339 | fde_val: 39.4558\n",
      "e: 21 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 16.7225 | ade_val: 23.0636 | fde_train: 26.7088 | fde_val: 46.8299\n",
      "e: 22 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 18.0516 | ade_val: 21.0007 | fde_train: 32.1940 | fde_val: 38.4217\n",
      "e: 23 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 16.4877 | ade_val: 22.1172 | fde_train: 29.0936 | fde_val: 43.9438\n",
      "e: 24 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 15.8872 | ade_val: 20.4523 | fde_train: 28.0540 | fde_val: 38.1940\n",
      "e: 25 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 14.9394 | ade_val: 19.8645 | fde_train: 23.7908 | fde_val: 38.4023\n",
      "e: 26 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 15.2145 | ade_val: 21.7027 | fde_train: 26.3990 | fde_val: 39.3712\n",
      "e: 27 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 16.2912 | ade_val: 20.4709 | fde_train: 30.5262 | fde_val: 38.0575\n",
      "e: 28 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 15.7656 | ade_val: 19.4830 | fde_train: 26.3136 | fde_val: 35.5807\n",
      "e: 29 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 15.7815 | ade_val: 19.5588 | fde_train: 27.6286 | fde_val: 36.3318\n",
      "e: 30 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 15.7802 | ade_val: 20.6361 | fde_train: 27.9335 | fde_val: 37.9419\n",
      "e: 31 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 15.7256 | ade_val: 19.5287 | fde_train: 27.5585 | fde_val: 36.5339\n",
      "e: 32 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 14.7022 | ade_val: 19.1759 | fde_train: 25.5631 | fde_val: 36.0108\n",
      "e: 33 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 14.3460 | ade_val: 19.6510 | fde_train: 24.6450 | fde_val: 37.1482\n",
      "e: 34 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 13.9793 | ade_val: 21.0455 | fde_train: 23.3513 | fde_val: 41.8420\n",
      "e: 35 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 15.3441 | ade_val: 19.3865 | fde_train: 25.6474 | fde_val: 34.1778\n",
      "e: 36 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 14.1682 | ade_val: 21.0231 | fde_train: 24.1654 | fde_val: 38.5126\n",
      "e: 37 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 13.5883 | ade_val: 19.6681 | fde_train: 22.8553 | fde_val: 36.5883\n",
      "e: 38 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 12.7176 | ade_val: 18.9234 | fde_train: 21.1436 | fde_val: 34.8610\n",
      "e: 39 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 13.1399 | ade_val: 19.4627 | fde_train: 22.0279 | fde_val: 34.8461\n",
      "e: 40 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 12.1602 | ade_val: 18.7617 | fde_train: 20.1086 | fde_val: 33.9420\n",
      "e: 41 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.9404 | ade_val: 18.2545 | fde_train: 19.1618 | fde_val: 32.4414\n",
      "e: 42 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.3046 | ade_val: 18.3188 | fde_train: 17.3087 | fde_val: 33.2821\n",
      "e: 43 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.2982 | ade_val: 18.4330 | fde_train: 17.8097 | fde_val: 32.5431\n",
      "e: 44 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.9936 | ade_val: 17.7871 | fde_train: 16.9858 | fde_val: 31.5796\n",
      "e: 45 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.9075 | ade_val: 18.6833 | fde_train: 17.1398 | fde_val: 35.3241\n",
      "e: 46 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.0657 | ade_val: 17.3284 | fde_train: 17.8559 | fde_val: 30.7344\n",
      "e: 47 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.6877 | ade_val: 17.9068 | fde_train: 16.4861 | fde_val: 32.1437\n",
      "e: 48 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.0586 | ade_val: 18.2568 | fde_train: 17.0590 | fde_val: 33.6605\n",
      "e: 49 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.3574 | ade_val: 16.8882 | fde_train: 18.1964 | fde_val: 30.7354\n",
      "e: 50 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.5584 | ade_val: 17.7527 | fde_train: 18.8858 | fde_val: 31.3600\n",
      "e: 51 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.9852 | ade_val: 17.6554 | fde_train: 16.5069 | fde_val: 30.6300\n",
      "e: 52 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 12.0860 | ade_val: 18.9551 | fde_train: 19.1399 | fde_val: 34.3281\n",
      "e: 53 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 12.4255 | ade_val: 18.8411 | fde_train: 21.0070 | fde_val: 32.8557\n",
      "e: 54 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.7723 | ade_val: 19.4841 | fde_train: 18.9947 | fde_val: 35.5109\n",
      "e: 55 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.2927 | ade_val: 18.1967 | fde_train: 17.2682 | fde_val: 34.6972\n",
      "e: 56 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.1867 | ade_val: 18.1296 | fde_train: 17.2111 | fde_val: 33.3819\n",
      "e: 57 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.1482 | ade_val: 17.3097 | fde_train: 17.3512 | fde_val: 31.6463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 58 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.3166 | ade_val: 18.9716 | fde_train: 17.3780 | fde_val: 35.0073\n",
      "e: 59 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.2448 | ade_val: 17.8731 | fde_train: 17.9314 | fde_val: 31.9117\n",
      "e: 60 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.2371 | ade_val: 19.5619 | fde_train: 17.1567 | fde_val: 37.8364\n",
      "e: 61 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.9516 | ade_val: 17.1256 | fde_train: 20.2845 | fde_val: 30.2833\n",
      "e: 62 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.5239 | ade_val: 17.6262 | fde_train: 17.5982 | fde_val: 32.5411\n",
      "e: 63 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.5254 | ade_val: 17.7185 | fde_train: 18.0135 | fde_val: 33.0944\n",
      "e: 64 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.6427 | ade_val: 17.5518 | fde_train: 18.5846 | fde_val: 31.6116\n",
      "Epoch    66: reducing learning rate of group 0 to 1.5000e-02.\n",
      "e: 65 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 12.2688 | ade_val: 17.5695 | fde_train: 19.2734 | fde_val: 32.4651\n",
      "e: 66 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.8952 | ade_val: 18.0895 | fde_train: 19.0927 | fde_val: 33.7586\n",
      "e: 67 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 12.0543 | ade_val: 18.0115 | fde_train: 19.3610 | fde_val: 32.9777\n",
      "e: 68 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.7589 | ade_val: 17.6558 | fde_train: 19.3567 | fde_val: 32.5072\n",
      "e: 69 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.6738 | ade_val: 18.3414 | fde_train: 19.4289 | fde_val: 32.2942\n",
      "e: 70 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.6832 | ade_val: 18.5997 | fde_train: 18.1788 | fde_val: 33.6976\n",
      "e: 71 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.9277 | ade_val: 18.0963 | fde_train: 19.4336 | fde_val: 32.1047\n",
      "e: 72 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.4963 | ade_val: 22.7667 | fde_train: 19.3686 | fde_val: 40.3445\n",
      "e: 73 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 13.6484 | ade_val: 20.8338 | fde_train: 23.3887 | fde_val: 44.5050\n",
      "e: 74 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 16.0483 | ade_val: 24.4279 | fde_train: 29.3982 | fde_val: 41.0684\n",
      "e: 75 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 14.8539 | ade_val: 21.0775 | fde_train: 22.1419 | fde_val: 39.9842\n",
      "e: 76 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 14.0176 | ade_val: 20.4300 | fde_train: 25.0982 | fde_val: 37.2444\n",
      "e: 77 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 12.8876 | ade_val: 20.3636 | fde_train: 19.7429 | fde_val: 35.6146\n",
      "e: 78 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.8444 | ade_val: 19.1736 | fde_train: 17.5416 | fde_val: 33.8506\n",
      "e: 79 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.4443 | ade_val: 19.2374 | fde_train: 17.5509 | fde_val: 34.4546\n",
      "e: 80 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.3879 | ade_val: 18.5080 | fde_train: 17.4340 | fde_val: 32.2585\n",
      "Epoch    82: reducing learning rate of group 0 to 7.5000e-03.\n",
      "e: 81 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 11.2237 | ade_val: 18.7559 | fde_train: 16.3581 | fde_val: 33.1959\n",
      "e: 82 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.8571 | ade_val: 18.4609 | fde_train: 15.8533 | fde_val: 33.1562\n",
      "e: 83 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.5715 | ade_val: 18.2659 | fde_train: 16.0408 | fde_val: 32.8643\n",
      "e: 84 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.3058 | ade_val: 18.1117 | fde_train: 15.1374 | fde_val: 32.1941\n",
      "e: 85 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.1593 | ade_val: 17.9344 | fde_train: 14.6042 | fde_val: 31.9637\n",
      "e: 86 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 10.0726 | ade_val: 17.8768 | fde_train: 14.4627 | fde_val: 31.4946\n",
      "e: 87 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.8990 | ade_val: 17.7717 | fde_train: 13.7963 | fde_val: 31.5695\n",
      "e: 88 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.8804 | ade_val: 17.5850 | fde_train: 13.9988 | fde_val: 31.5089\n",
      "e: 89 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.7029 | ade_val: 17.5523 | fde_train: 13.7212 | fde_val: 31.2796\n",
      "e: 90 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.6540 | ade_val: 17.2594 | fde_train: 13.5203 | fde_val: 30.8880\n",
      "e: 91 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.5627 | ade_val: 17.2182 | fde_train: 13.3964 | fde_val: 30.7500\n",
      "e: 92 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.5053 | ade_val: 16.9597 | fde_train: 13.0330 | fde_val: 30.0906\n",
      "e: 93 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.3453 | ade_val: 16.7428 | fde_train: 12.6073 | fde_val: 29.6366\n",
      "e: 94 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.3269 | ade_val: 16.8538 | fde_train: 12.7734 | fde_val: 30.0174\n",
      "e: 95 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.2303 | ade_val: 16.5889 | fde_train: 12.4408 | fde_val: 28.7179\n",
      "e: 96 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.3895 | ade_val: 16.3963 | fde_train: 12.8811 | fde_val: 28.7507\n",
      "Epoch    98: reducing learning rate of group 0 to 3.7500e-03.\n",
      "e: 97 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.5180 | ade_val: 17.0696 | fde_train: 13.7718 | fde_val: 30.3469\n",
      "e: 98 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.5722 | ade_val: 17.2285 | fde_train: 13.3428 | fde_val: 30.6766\n",
      "e: 99 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.3648 | ade_val: 17.4040 | fde_train: 12.7667 | fde_val: 31.2177\n",
      "e: 100 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.3958 | ade_val: 17.4409 | fde_train: 12.8272 | fde_val: 31.3347\n",
      "e: 101 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.2377 | ade_val: 17.5051 | fde_train: 12.4701 | fde_val: 31.5173\n",
      "e: 102 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.1837 | ade_val: 17.6079 | fde_train: 12.4988 | fde_val: 31.6733\n",
      "e: 103 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.1899 | ade_val: 17.6497 | fde_train: 12.5442 | fde_val: 31.8797\n",
      "e: 104 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.1809 | ade_val: 17.7527 | fde_train: 12.5853 | fde_val: 31.8641\n",
      "e: 105 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.1410 | ade_val: 18.4705 | fde_train: 12.5075 | fde_val: 33.5995\n",
      "e: 106 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.0943 | ade_val: 18.6699 | fde_train: 12.1155 | fde_val: 33.9808\n",
      "e: 107 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.0406 | ade_val: 17.9920 | fde_train: 11.9839 | fde_val: 32.4227\n",
      "e: 108 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 9.0000 | ade_val: 18.1703 | fde_train: 12.1241 | fde_val: 33.5659\n",
      "e: 109 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.9707 | ade_val: 17.8623 | fde_train: 12.0079 | fde_val: 32.3311\n",
      "e: 110 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.9599 | ade_val: 18.3307 | fde_train: 11.8608 | fde_val: 33.8248\n",
      "e: 111 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.8970 | ade_val: 18.4712 | fde_train: 11.8198 | fde_val: 33.9003\n",
      "e: 112 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.8545 | ade_val: 18.4518 | fde_train: 11.8497 | fde_val: 33.7113\n",
      "Epoch   114: reducing learning rate of group 0 to 1.8750e-03.\n",
      "e: 113 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.8499 | ade_val: 18.5021 | fde_train: 11.7909 | fde_val: 33.7845\n",
      "e: 114 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.8053 | ade_val: 18.4327 | fde_train: 11.8011 | fde_val: 33.6646\n",
      "e: 115 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.8318 | ade_val: 18.4047 | fde_train: 11.8651 | fde_val: 33.6026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 116 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.7959 | ade_val: 18.3443 | fde_train: 11.6857 | fde_val: 33.3674\n",
      "e: 117 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.7813 | ade_val: 18.4000 | fde_train: 11.5159 | fde_val: 33.4073\n",
      "e: 118 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.7644 | ade_val: 18.3886 | fde_train: 11.3549 | fde_val: 33.4002\n",
      "e: 119 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.7429 | ade_val: 18.4324 | fde_train: 11.3797 | fde_val: 33.4466\n",
      "e: 120 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.7179 | ade_val: 18.4260 | fde_train: 11.3509 | fde_val: 33.4308\n",
      "e: 121 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.7060 | ade_val: 18.3956 | fde_train: 11.2767 | fde_val: 33.4406\n",
      "e: 122 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.6700 | ade_val: 18.3724 | fde_train: 11.2119 | fde_val: 33.4590\n",
      "e: 123 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.6531 | ade_val: 18.3594 | fde_train: 11.2151 | fde_val: 33.5390\n",
      "e: 124 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.6398 | ade_val: 18.3715 | fde_train: 11.2079 | fde_val: 33.4521\n",
      "e: 125 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5986 | ade_val: 18.3601 | fde_train: 11.0751 | fde_val: 33.4237\n",
      "e: 126 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5966 | ade_val: 18.3784 | fde_train: 11.0448 | fde_val: 33.4661\n",
      "e: 127 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5878 | ade_val: 18.3779 | fde_train: 11.0454 | fde_val: 33.5049\n",
      "e: 128 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5793 | ade_val: 18.3685 | fde_train: 11.0570 | fde_val: 33.4710\n",
      "Epoch   130: reducing learning rate of group 0 to 9.3750e-04.\n",
      "e: 129 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5487 | ade_val: 18.3576 | fde_train: 10.9828 | fde_val: 33.4481\n",
      "e: 130 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5280 | ade_val: 18.3548 | fde_train: 10.9092 | fde_val: 33.4090\n",
      "e: 131 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5470 | ade_val: 18.3246 | fde_train: 10.9673 | fde_val: 33.3470\n",
      "e: 132 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5224 | ade_val: 18.3349 | fde_train: 10.9101 | fde_val: 33.3427\n",
      "e: 133 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5151 | ade_val: 18.3308 | fde_train: 10.9153 | fde_val: 33.3143\n",
      "e: 134 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5003 | ade_val: 18.3257 | fde_train: 10.8938 | fde_val: 33.3335\n",
      "e: 135 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4868 | ade_val: 18.2968 | fde_train: 10.8608 | fde_val: 33.2864\n",
      "e: 136 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5100 | ade_val: 18.2417 | fde_train: 10.8779 | fde_val: 33.1867\n",
      "e: 137 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.5134 | ade_val: 18.2336 | fde_train: 10.8928 | fde_val: 33.1843\n",
      "e: 138 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4913 | ade_val: 18.2994 | fde_train: 10.8576 | fde_val: 33.4909\n",
      "e: 139 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4772 | ade_val: 18.2551 | fde_train: 10.8053 | fde_val: 33.2214\n",
      "e: 140 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4849 | ade_val: 18.1754 | fde_train: 10.8497 | fde_val: 33.1548\n",
      "e: 141 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4798 | ade_val: 18.1618 | fde_train: 10.8348 | fde_val: 33.1327\n",
      "e: 142 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4647 | ade_val: 18.1736 | fde_train: 10.7996 | fde_val: 33.2147\n",
      "e: 143 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4545 | ade_val: 18.1195 | fde_train: 10.7914 | fde_val: 33.1250\n",
      "e: 144 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4477 | ade_val: 18.1166 | fde_train: 10.7936 | fde_val: 33.1436\n",
      "Epoch   146: reducing learning rate of group 0 to 4.6875e-04.\n",
      "e: 145 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4515 | ade_val: 18.1029 | fde_train: 10.7648 | fde_val: 33.1485\n",
      "e: 146 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4346 | ade_val: 18.0723 | fde_train: 10.7471 | fde_val: 33.0747\n",
      "e: 147 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4259 | ade_val: 17.9606 | fde_train: 10.7617 | fde_val: 32.9505\n",
      "e: 148 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4487 | ade_val: 17.8012 | fde_train: 10.7848 | fde_val: 32.4174\n",
      "e: 149 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4156 | ade_val: 17.8922 | fde_train: 10.7182 | fde_val: 32.8051\n",
      "e: 150 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4245 | ade_val: 17.8925 | fde_train: 10.7461 | fde_val: 32.8024\n",
      "e: 151 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4040 | ade_val: 17.8900 | fde_train: 10.6977 | fde_val: 32.7979\n",
      "e: 152 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4028 | ade_val: 17.8829 | fde_train: 10.6904 | fde_val: 32.7809\n",
      "e: 153 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4162 | ade_val: 17.8657 | fde_train: 10.7140 | fde_val: 32.7414\n",
      "e: 154 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4093 | ade_val: 17.8522 | fde_train: 10.6981 | fde_val: 32.7247\n",
      "e: 155 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4156 | ade_val: 17.7085 | fde_train: 10.7405 | fde_val: 32.0055\n",
      "e: 156 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4050 | ade_val: 17.7990 | fde_train: 10.6950 | fde_val: 32.5997\n",
      "e: 157 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4040 | ade_val: 17.7575 | fde_train: 10.6849 | fde_val: 32.5781\n",
      "e: 158 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4464 | ade_val: 17.7061 | fde_train: 10.7690 | fde_val: 32.3622\n",
      "e: 159 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4531 | ade_val: 17.6646 | fde_train: 10.7878 | fde_val: 32.0608\n",
      "e: 160 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4246 | ade_val: 17.6317 | fde_train: 10.7742 | fde_val: 31.9148\n",
      "Epoch   162: reducing learning rate of group 0 to 2.3437e-04.\n",
      "e: 161 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4291 | ade_val: 17.6223 | fde_train: 10.7758 | fde_val: 31.8929\n",
      "e: 162 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4177 | ade_val: 17.6213 | fde_train: 10.7700 | fde_val: 31.9036\n",
      "e: 163 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4169 | ade_val: 17.6593 | fde_train: 10.7933 | fde_val: 32.2472\n",
      "e: 164 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4209 | ade_val: 17.7376 | fde_train: 10.7641 | fde_val: 32.5869\n",
      "e: 165 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4133 | ade_val: 17.7589 | fde_train: 10.7643 | fde_val: 32.6178\n",
      "e: 166 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4181 | ade_val: 17.7958 | fde_train: 10.7634 | fde_val: 32.7362\n",
      "e: 167 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4404 | ade_val: 17.7944 | fde_train: 10.8042 | fde_val: 32.7262\n",
      "e: 168 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4073 | ade_val: 17.7636 | fde_train: 10.7598 | fde_val: 32.6558\n",
      "e: 169 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3956 | ade_val: 17.7550 | fde_train: 10.7336 | fde_val: 32.6616\n",
      "e: 170 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4040 | ade_val: 17.7405 | fde_train: 10.7500 | fde_val: 32.6300\n",
      "e: 171 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.4118 | ade_val: 17.7261 | fde_train: 10.7538 | fde_val: 32.5956\n",
      "e: 172 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3984 | ade_val: 17.7129 | fde_train: 10.7406 | fde_val: 32.5738\n",
      "e: 173 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3907 | ade_val: 17.7006 | fde_train: 10.7150 | fde_val: 32.5631\n",
      "e: 174 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3980 | ade_val: 17.6833 | fde_train: 10.7441 | fde_val: 32.5783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 175 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3786 | ade_val: 17.6601 | fde_train: 10.7130 | fde_val: 32.5663\n",
      "e: 176 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3843 | ade_val: 17.6444 | fde_train: 10.6983 | fde_val: 32.5628\n",
      "Epoch   178: reducing learning rate of group 0 to 1.1719e-04.\n",
      "e: 177 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3593 | ade_val: 17.6349 | fde_train: 10.6752 | fde_val: 32.5749\n",
      "e: 178 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3660 | ade_val: 17.6304 | fde_train: 10.6965 | fde_val: 32.5696\n",
      "e: 179 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3667 | ade_val: 17.6268 | fde_train: 10.6921 | fde_val: 32.5610\n",
      "e: 180 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3619 | ade_val: 17.6220 | fde_train: 10.6586 | fde_val: 32.5483\n",
      "e: 181 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3642 | ade_val: 17.6175 | fde_train: 10.6491 | fde_val: 32.5288\n",
      "e: 182 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3553 | ade_val: 17.6089 | fde_train: 10.6545 | fde_val: 32.4909\n",
      "e: 183 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3521 | ade_val: 17.6019 | fde_train: 10.6415 | fde_val: 32.4622\n",
      "e: 184 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3544 | ade_val: 17.5968 | fde_train: 10.6337 | fde_val: 32.4461\n",
      "e: 185 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3552 | ade_val: 17.5929 | fde_train: 10.6447 | fde_val: 32.4332\n",
      "e: 186 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3520 | ade_val: 17.5907 | fde_train: 10.6194 | fde_val: 32.4246\n",
      "e: 187 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3598 | ade_val: 17.5887 | fde_train: 10.6330 | fde_val: 32.4164\n",
      "e: 188 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3399 | ade_val: 17.5842 | fde_train: 10.6147 | fde_val: 32.4047\n",
      "e: 189 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3544 | ade_val: 17.5724 | fde_train: 10.6332 | fde_val: 32.3748\n",
      "e: 190 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3609 | ade_val: 17.5648 | fde_train: 10.6383 | fde_val: 32.3566\n",
      "e: 191 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3523 | ade_val: 17.5627 | fde_train: 10.6414 | fde_val: 32.3472\n",
      "e: 192 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3490 | ade_val: 17.5736 | fde_train: 10.6207 | fde_val: 32.3681\n",
      "Epoch   194: reducing learning rate of group 0 to 5.8594e-05.\n",
      "e: 193 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3604 | ade_val: 17.5784 | fde_train: 10.6258 | fde_val: 32.3798\n",
      "e: 194 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3418 | ade_val: 17.5795 | fde_train: 10.5988 | fde_val: 32.3846\n",
      "e: 195 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3537 | ade_val: 17.5755 | fde_train: 10.6452 | fde_val: 32.3685\n",
      "e: 196 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3457 | ade_val: 17.5664 | fde_train: 10.6230 | fde_val: 32.3501\n",
      "e: 197 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3454 | ade_val: 17.5586 | fde_train: 10.6231 | fde_val: 32.3328\n",
      "e: 198 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3559 | ade_val: 17.5544 | fde_train: 10.6409 | fde_val: 32.3272\n",
      "e: 199 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3450 | ade_val: 17.5503 | fde_train: 10.6077 | fde_val: 32.3184\n",
      "e: 200 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3361 | ade_val: 17.4964 | fde_train: 10.6043 | fde_val: 32.0849\n",
      "e: 201 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3508 | ade_val: 17.5262 | fde_train: 10.6198 | fde_val: 32.2499\n",
      "e: 202 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3329 | ade_val: 17.5672 | fde_train: 10.5783 | fde_val: 32.3735\n",
      "e: 203 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3369 | ade_val: 17.5397 | fde_train: 10.5991 | fde_val: 32.2997\n",
      "e: 204 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3488 | ade_val: 17.4630 | fde_train: 10.6100 | fde_val: 31.8152\n",
      "e: 205 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3371 | ade_val: 17.4461 | fde_train: 10.5946 | fde_val: 31.7405\n",
      "e: 206 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3342 | ade_val: 17.4306 | fde_train: 10.6031 | fde_val: 31.5605\n",
      "e: 207 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3538 | ade_val: 17.4710 | fde_train: 10.6207 | fde_val: 31.7865\n",
      "e: 208 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3512 | ade_val: 17.4802 | fde_train: 10.6032 | fde_val: 31.8204\n",
      "Epoch   210: reducing learning rate of group 0 to 2.9297e-05.\n",
      "e: 209 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3265 | ade_val: 17.5394 | fde_train: 10.5878 | fde_val: 32.1463\n",
      "e: 210 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3381 | ade_val: 17.6040 | fde_train: 10.6020 | fde_val: 32.4062\n",
      "e: 211 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3465 | ade_val: 17.6365 | fde_train: 10.6036 | fde_val: 32.4887\n",
      "e: 212 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3469 | ade_val: 17.6506 | fde_train: 10.6252 | fde_val: 32.5294\n",
      "e: 213 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3426 | ade_val: 17.6595 | fde_train: 10.6219 | fde_val: 32.5511\n",
      "e: 214 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3338 | ade_val: 17.6637 | fde_train: 10.5954 | fde_val: 32.5557\n",
      "e: 215 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3487 | ade_val: 17.7123 | fde_train: 10.6168 | fde_val: 32.6809\n",
      "e: 216 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3205 | ade_val: 17.7598 | fde_train: 10.5665 | fde_val: 32.8033\n",
      "e: 217 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3308 | ade_val: 17.8343 | fde_train: 10.5951 | fde_val: 32.8893\n",
      "e: 218 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3452 | ade_val: 17.8582 | fde_train: 10.6085 | fde_val: 32.9181\n",
      "e: 219 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3462 | ade_val: 17.8667 | fde_train: 10.6019 | fde_val: 32.9316\n",
      "e: 220 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3324 | ade_val: 17.8724 | fde_train: 10.5801 | fde_val: 32.9433\n",
      "e: 221 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3329 | ade_val: 17.8750 | fde_train: 10.5880 | fde_val: 32.9499\n",
      "e: 222 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3373 | ade_val: 17.8760 | fde_train: 10.5954 | fde_val: 32.9516\n",
      "e: 223 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3483 | ade_val: 17.8758 | fde_train: 10.6268 | fde_val: 32.9493\n",
      "e: 224 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3245 | ade_val: 17.8752 | fde_train: 10.5710 | fde_val: 32.9468\n",
      "Epoch   226: reducing learning rate of group 0 to 1.4648e-05.\n",
      "e: 225 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3204 | ade_val: 17.8749 | fde_train: 10.5649 | fde_val: 32.9459\n",
      "e: 226 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3418 | ade_val: 17.8747 | fde_train: 10.5917 | fde_val: 32.9454\n",
      "e: 227 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3333 | ade_val: 17.8745 | fde_train: 10.5847 | fde_val: 32.9452\n",
      "e: 228 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3446 | ade_val: 17.8744 | fde_train: 10.6099 | fde_val: 32.9449\n",
      "e: 229 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3200 | ade_val: 17.8742 | fde_train: 10.5696 | fde_val: 32.9444\n",
      "e: 230 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3465 | ade_val: 17.8740 | fde_train: 10.6200 | fde_val: 32.9436\n",
      "e: 231 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3352 | ade_val: 17.8739 | fde_train: 10.5774 | fde_val: 32.9429\n",
      "e: 232 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3323 | ade_val: 17.8735 | fde_train: 10.5732 | fde_val: 32.9417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 233 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3256 | ade_val: 17.8730 | fde_train: 10.5802 | fde_val: 32.9401\n",
      "e: 234 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3300 | ade_val: 17.8722 | fde_train: 10.5925 | fde_val: 32.9379\n",
      "e: 235 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3292 | ade_val: 17.8708 | fde_train: 10.5740 | fde_val: 32.9355\n",
      "e: 236 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3347 | ade_val: 17.8683 | fde_train: 10.5826 | fde_val: 32.9321\n",
      "e: 237 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3278 | ade_val: 17.8656 | fde_train: 10.5758 | fde_val: 32.9292\n",
      "e: 238 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3268 | ade_val: 17.8592 | fde_train: 10.5777 | fde_val: 32.9196\n",
      "e: 239 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3374 | ade_val: 17.8450 | fde_train: 10.5984 | fde_val: 32.8690\n",
      "e: 240 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3419 | ade_val: 17.8425 | fde_train: 10.5833 | fde_val: 32.8952\n",
      "Epoch   242: reducing learning rate of group 0 to 7.3242e-06.\n",
      "e: 241 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3318 | ade_val: 17.8402 | fde_train: 10.5864 | fde_val: 32.9039\n",
      "e: 242 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3203 | ade_val: 17.8403 | fde_train: 10.5688 | fde_val: 32.9195\n",
      "e: 243 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3182 | ade_val: 17.8431 | fde_train: 10.5586 | fde_val: 32.9651\n",
      "e: 244 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3366 | ade_val: 17.8598 | fde_train: 10.6074 | fde_val: 33.0704\n",
      "e: 245 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3184 | ade_val: 17.8539 | fde_train: 10.5608 | fde_val: 33.0836\n",
      "e: 246 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3185 | ade_val: 17.8373 | fde_train: 10.5564 | fde_val: 33.0563\n",
      "e: 247 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3363 | ade_val: 17.8041 | fde_train: 10.5799 | fde_val: 32.9101\n",
      "e: 248 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3394 | ade_val: 17.7895 | fde_train: 10.5977 | fde_val: 32.8686\n",
      "e: 249 | ts: 0.0000 | tg: 0.0000 | vs: 0.0000 | vg: 0.0000 | ade_train: 8.3249 | ade_val: 17.7732 | fde_train: 10.5632 | fde_val: 32.8130\n",
      "====================================================================================================\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    " \n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms, utils\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class PV_LSTM_DE_pose(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        '''\n",
    "           input: observed body poses and velocites global and local\n",
    "           output: global and local velocities\n",
    "        '''\n",
    "        super(PV_LSTM_DE_pose, self).__init__()\n",
    "         \n",
    "        self.pose_encoder = nn.LSTM(input_size=34, hidden_size=args.hidden_size)\n",
    "        self.pose_embedding = nn.Sequential(nn.Linear(in_features=args.hidden_size, out_features=34),\n",
    "                                           nn.ReLU())\n",
    "        self.pose_decoder = nn.LSTMCell(input_size=34, hidden_size=args.hidden_size)\n",
    "        self.fc_pose   = nn.Linear(in_features=args.hidden_size, out_features=34)\n",
    "        \n",
    "        self.vel_encoder = nn.LSTM(input_size=34, hidden_size=args.hidden_size)\n",
    "        self.vel_decoder = nn.LSTMCell(input_size=34, hidden_size=args.hidden_size)\n",
    "        self.fc_vel    = nn.Linear(in_features=args.hidden_size, out_features=34)\n",
    "        \n",
    "        self.pose_glob_encoder = nn.LSTM(input_size=2, hidden_size=100)\n",
    "        self.vel_glob_encoder = nn.LSTM(input_size=2, hidden_size=100)\n",
    "        self.vel_glob_decoder = nn.LSTMCell(input_size=2, hidden_size=100)\n",
    "        self.fc_global    = nn.Linear(in_features=100, out_features=2)\n",
    "       \n",
    "        \n",
    "        self.hardtanh = nn.Hardtanh(min_val=-1*args.hardtanh_limit,max_val=args.hardtanh_limit)\n",
    "        self.relu = nn.ReLU() \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "        self.args = args\n",
    "        \n",
    "    def forward(self, pose=None, vel=None, pose_glob=None, vel_glob=None):\n",
    "\n",
    "\n",
    "        _, (hidden_vel, cell_vel) = self.vel_encoder(vel.permute(1,0,2))\n",
    "        hidden_vel = hidden_vel.squeeze(0)\n",
    "        cell_vel = cell_vel.squeeze(0)\n",
    "\n",
    "\n",
    "        _, (hidden_pose, cell_pose) = self.pose_encoder(pose.permute(1,0,2))\n",
    "        hidden_pose = hidden_pose.squeeze(0)\n",
    "        cell_pose = cell_pose.squeeze(0)\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "      \n",
    "        #predicting the velocity of poses and poses\n",
    "        vel_outputs    = torch.tensor([], device=self.args.device)\n",
    "        pose_outputs   = torch.tensor([], device=self.args.device)\n",
    "        glob_outputs    = torch.tensor([], device=self.args.device)\n",
    "\n",
    "        VelDec_inp = vel[:,-1,:]\n",
    "        PoseDec_inp = pose[:,-1,:]\n",
    "        \n",
    "        hidden_dec = hidden_pose + hidden_vel\n",
    "        cell_dec = cell_pose + cell_vel\n",
    "         \n",
    "#         outputs.append(vel_outputs)\n",
    "        for i in range(self.args.output//self.args.skip):\n",
    "            hidden_dec, cell_dec = self.vel_decoder(VelDec_inp, (hidden_dec, cell_dec))\n",
    "            vel_output  = self.hardtanh(self.fc_vel(hidden_dec))\n",
    "#             vel_outputs = torch.cat((vel_outputs, vel_output.unsqueeze(1)), dim = 1)\n",
    "            \n",
    "            pose_output = PoseDec_inp + VelDec_inp\n",
    "            pose_outputs = torch.cat((pose_outputs, pose_output.unsqueeze(1)), dim = 1)\n",
    "            PoseDec_inp = pose_output\n",
    "            VelDec_inp  = vel_output\n",
    "                   \n",
    "        outputs.append(pose_outputs)\n",
    "#         in_pose = pose[:,-1,:]\n",
    "          \n",
    "#         hdp = hidden_pose + hidden_vel\n",
    "#         cdp = cell_pose + cell_vel\n",
    "#         for i in range(self.args.output//self.args.skip):\n",
    "#             hdp, cdp     = self.pose_decoder(in_pose, (hdp, cdp))\n",
    "#             pose_output  = self.fc_pose(hdp)\n",
    "# #             in_pose      = self.pose_embedding(hdp).detach()\n",
    "# #             pose_output  = self.softmax(pose_output)\n",
    "# #             pose_outputs = torch.cat((pose_outputs, pose_output.unsqueeze(1)), dim = 1)\n",
    "#             pose_output = PoseDec_inp + VelDec_inp \n",
    "#             in_pose  = pose_output\n",
    "            \n",
    "#             pose_outputs = torch.cat((pose_outputs, pose_output.unsqueeze(1)), dim = 1)\n",
    "# #             PoseDec_inp = pose_output\n",
    "\n",
    "#         outputs.append(pose_outputs)\n",
    "    \n",
    "        \n",
    "        \n",
    "#         _, (hidden_vel_glob, cell_vel_glob) = self.vel_glob_encoder(vel_glob.permute(1,0,2))\n",
    "#         hidden_vel_glob = hidden_vel_glob.squeeze(0)\n",
    "#         cell_vel_glob = cell_vel_glob.squeeze(0)\n",
    "        \n",
    "#         _, (hidden_pose_glob, cell_pose_glob) = self.pose_glob_encoder(pose_glob.permute(1,0,2))\n",
    "#         hidden_pose_glob = hidden_pose_glob.squeeze(0)\n",
    "#         cell_pose_glob = cell_pose_glob.squeeze(0)\n",
    "        \n",
    "#         glob_inp = pose_glob[:,-1,:]\n",
    "        \n",
    "#         hidden_glob = hidden_pose_glob + hidden_vel_glob\n",
    "#         cell_glob = cell_pose_glob + cell_vel_glob\n",
    "#         for i in range(self.args.output//self.args.skip):\n",
    "#             hidden_glob, cell_glob = self.vel_glob_decoder(glob_inp, (hidden_glob, cell_glob))\n",
    "#             glob_output  = self.fc_global(hidden_glob)\n",
    "#             glob_outputs = torch.cat((glob_outputs, glob_output.unsqueeze(1)), dim = 1)\n",
    "#             glob_inp  = glob_output.detach()\n",
    "       \n",
    "#         outputs.append(glob_outputs)\n",
    "        \n",
    "       \n",
    "        return tuple(outputs)\n",
    "\n",
    "class myDataset_DE(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, dtype):\n",
    "        \n",
    "        self.args = args\n",
    "        self.dtype = dtype\n",
    "        print(\"Loading\",self.dtype)\n",
    "        \n",
    "        sequence_centric = pd.read_csv(\"sequences_openpifpaf_\"+self.dtype+\".csv\")\n",
    "#         sequence_centric = pd.read_csv(\"sequences_4_\"+self.dtype+\".csv\")\n",
    "\n",
    "        df = sequence_centric.copy()      \n",
    "        for v in list(df.columns.values):\n",
    "            print(v+' loaded')\n",
    "            try:\n",
    "                df.loc[:,v] = df.loc[:, v].apply(lambda x: literal_eval(x))\n",
    "            except:\n",
    "                continue\n",
    "        sequence_centric[df.columns] = df[df.columns]\n",
    "        self.data = sequence_centric.copy().reset_index(drop=True)\n",
    "    \n",
    "        print('*'*30)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        seq = self.data.iloc[index]\n",
    "        outputs = []\n",
    "\n",
    "        obs = torch.tensor([seq.Pose[i] for i in range(0,self.args.input,self.args.skip)])        \n",
    "        obs_speed = (obs[1:] - obs[:-1])\n",
    "        \n",
    "        true = torch.tensor([seq.Future_Pose[i] for i in range(0,self.args.output,self.args.skip)])\n",
    "        true_speed = torch.cat(((true[0]-obs[-1]).unsqueeze(0), true[1:]-true[:-1]))\n",
    "        \n",
    "        outputs.append(obs_speed)\n",
    "        outputs.append(true_speed)\n",
    "       \n",
    "        obs_resh = torch.reshape(obs, (obs.size()[0],17,2))\n",
    "        \n",
    "        obs_global=(obs_resh[:,5]+obs_resh[:,6])/2.0\n",
    "        obs_global=obs_global.unsqueeze(1)\n",
    "\n",
    "        obs_resh=obs_resh-obs_global\n",
    "    \n",
    "        obs_resh=obs_resh.reshape(obs.size())\n",
    "        \n",
    "        true_resh = torch.reshape(true, (true.size()[0],17,2))\n",
    "        true_global=(true_resh[:,5]+true_resh[:,6])/2.0\n",
    "        true_global=true_global.unsqueeze(1)\n",
    "        \n",
    "        true_resh=true_resh-true_global\n",
    "        true_resh=true_resh.reshape(true.size())\n",
    "        \n",
    "        obs_global=torch.reshape(obs_global, (obs.size()[0],2))\n",
    "        true_global=torch.reshape(true_global, (true.size()[0],2))\n",
    "        \n",
    "        obs_global_speed = (obs_global[1:] - obs_global[:-1])\n",
    "        true_global_speed = torch.cat(((true_global[0]-obs_global[-1]).unsqueeze(0), true_global[1:]-true_global[:-1]))\n",
    "        \n",
    "\n",
    "        \n",
    "        outputs.append(obs_resh)\n",
    "        outputs.append(true_resh)\n",
    "        outputs.append(obs_global)\n",
    "        outputs.append(true_global)\n",
    "        outputs.append(obs_global_speed)\n",
    "        outputs.append(true_global_speed)\n",
    "        outputs.append(true)\n",
    "\n",
    "        \n",
    "        return tuple(outputs)    \n",
    "    \n",
    "    \n",
    "def data_loader_DE(args,data):\n",
    "    dataset = myDataset_DE(args,data)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=args.batch_size, shuffle=args.loader_shuffle,\n",
    "        pin_memory=args.pin_memory)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "class myDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, dtype):\n",
    "        \n",
    "        self.args = args\n",
    "        self.dtype = dtype\n",
    "        print(\"Loading\",self.dtype)\n",
    "        \n",
    "        sequence_centric = pd.read_csv(\"sequences_openpifpaf_\"+self.dtype+\".csv\")\n",
    "#         sequence_centric = pd.read_csv(\"sequences_4_\"+self.dtype+\".csv\")\n",
    "\n",
    "        df = sequence_centric.copy()      \n",
    "        for v in list(df.columns.values):\n",
    "            print(v+' loaded')\n",
    "            try:\n",
    "                df.loc[:,v] = df.loc[:, v].apply(lambda x: literal_eval(x))\n",
    "            except:\n",
    "                continue\n",
    "        sequence_centric[df.columns] = df[df.columns]\n",
    "        self.data = sequence_centric.copy().reset_index(drop=True)\n",
    "    \n",
    "        print('*'*30)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        seq = self.data.iloc[index]\n",
    "        outputs = []\n",
    "\n",
    "#         observed = torch.tensor(np.array(seq.Pose))\n",
    "#         future = torch.tensor(np.array(seq.Future_Pose))\n",
    "        \n",
    "        \n",
    "\n",
    "        obs = torch.tensor([seq.Pose[i] for i in range(0,self.args.input,self.args.skip)])\n",
    "        #obs and future global avg of joint 5 & 6 (0 indexed) for openpifpaf\n",
    "        #local = obs pose-global  for openpifpaf\n",
    "        \n",
    "        obs_speed = (obs[1:] - obs[:-1])\n",
    "    \n",
    "        outputs.append(obs_speed)\n",
    "        \n",
    "        \n",
    "        true = torch.tensor([seq.Future_Pose[i] for i in range(0,self.args.output,self.args.skip)])\n",
    "        true_speed = torch.cat(((true[0]-obs[-1]).unsqueeze(0), true[1:]-true[:-1]))\n",
    "\n",
    "\n",
    "        outputs.append(true_speed)\n",
    "        outputs.append(obs)\n",
    "        outputs.append(true)\n",
    "        \n",
    "        return tuple(outputs)    \n",
    "    \n",
    "    \n",
    "def data_loader(args,data):\n",
    "    dataset = myDataset(args,data)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=args.batch_size, shuffle=args.loader_shuffle,\n",
    "        pin_memory=args.pin_memory)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import utils\n",
    "from sklearn.metrics import recall_score, accuracy_score, average_precision_score, precision_score\n",
    "\n",
    "# import DataLoader\n",
    "# import network\n",
    "# import utils\n",
    "\n",
    "class args():\n",
    "    def __init__(self):\n",
    "        self.jaad_dataset = '/data/smailait-data/JAAD/processed_annotations' #folder containing parsed jaad annotations (used when first time loading data)\n",
    "        self.dtype        = 'train'\n",
    "        self.from_file    = False #read dataset from csv file or reprocess data\n",
    "        self.save         = True\n",
    "        self.file         = '/data/smailait-data/jaad_train_16_16.csv'\n",
    "        self.save_path    = '/data/smailait-data/jaad_train_16_16.csv'\n",
    "        self.model_path    = '/data/smailait-data/models/multitask_pv_lstm_trained.pkl'\n",
    "        self.loader_workers = 1\n",
    "        self.loader_shuffle = True\n",
    "        self.pin_memory     = False\n",
    "        self.image_resize   = [240, 426]\n",
    "        self.device         = 'cuda'\n",
    "        self.batch_size     = 50\n",
    "        self.n_epochs       = 250\n",
    "        self.hidden_size    = 1000\n",
    "        self.hardtanh_limit = 100\n",
    "        self.input  = 16\n",
    "        self.output = 16\n",
    "        self.stride = 16\n",
    "        self.skip   = 1\n",
    "        # self.task   = 'bounding_box-intention'\n",
    "        self.task   = 'pose'\n",
    "        self.use_scenes = False       \n",
    "        self.lr = 0.03\n",
    "        \n",
    "args = args()\n",
    "\n",
    "net = PV_LSTM_DE_pose(args).to(args.device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=15, \n",
    "                                                 threshold = 1e-8, verbose=True)\n",
    "mse = nn.MSELoss()\n",
    "bce = nn.BCELoss()\n",
    "l1e = nn.L1Loss()\n",
    "train_s_scores = []\n",
    "train_pose_scores=[]\n",
    "val_pose_scores=[]\n",
    "train_c_scores = []\n",
    "val_s_scores   = []\n",
    "val_c_scores   = []\n",
    "train_g_scores = []\n",
    "val_g_scores   = []\n",
    "\n",
    "train_loader=data_loader(args,\"train\")\n",
    "val_loader=data_loader(args,\"val\" )\n",
    "\n",
    "def speed2pos_glob(preds, glob_pred, obs_p, obs_global) :\n",
    "    pred_pos = torch.zeros(preds.shape[0], preds.shape[1], 34).to('cuda')\n",
    "\n",
    "    current = (obs_p[:,-1,:].reshape(-1,17,2)+ obs_global[:,-1,:].reshape(-1,1,2)).reshape(-1,34)\n",
    "    \n",
    "    for i in range(preds.shape[1]):\n",
    "        pred_pos[:,i,:] = ((current + preds[:,i,:]).reshape(current.size()[0],17,2)+glob_pred[:,i,:].reshape(-1,1,2)).reshape(-1,34)\n",
    "        current = pred_pos[:,i,:]\n",
    "        \n",
    "    for i in range(34):\n",
    "        pred_pos[:,:,i] = torch.min(pred_pos[:,:,i], 1920*torch.ones(pred_pos.shape[0], pred_pos.shape[1], device='cuda'))\n",
    "        pred_pos[:,:,i] = torch.max(pred_pos[:,:,i], torch.zeros(pred_pos.shape[0], pred_pos.shape[1], device='cuda'))\n",
    "        \n",
    "    return pred_pos\n",
    "\n",
    "def ADE_c_DE(pred, true):\n",
    "    pred = torch.reshape(pred, (pred.size()[0],pred.size()[1],1,2))\n",
    "    true = torch.reshape(true, (true.size()[0],true.size()[1],1,2))\n",
    "    \n",
    "    displacement=torch.sqrt((pred[:,:,:,0]-true[:,:,:,0])**2+(pred[:,:,:,1]-true[:,:,:,1])**2)\n",
    "    ade = torch.mean(torch.mean(displacement,dim=1))\n",
    "\n",
    "    return ade\n",
    "\n",
    "\n",
    "def FDE_c_DE(pred, true):\n",
    "    pred = torch.reshape(pred, (pred.size()[0],pred.size()[1],1,2))\n",
    "    true = torch.reshape(true, (true.size()[0],true.size()[1],1,2))\n",
    "    \n",
    "    displacement=torch.sqrt((pred[:,-1,:,0]-true[:,-1,:,0])**2+(pred[:,-1,:,1]-true[:,-1,:,1])**2)\n",
    "\n",
    "    fde = torch.mean(torch.mean(displacement,dim=1))\n",
    "    \n",
    "    return fde\n",
    "\n",
    "def ADE_c(pred, true):\n",
    "    pred = torch.reshape(pred, (pred.size()[0],pred.size()[1],17,2))\n",
    "    true = torch.reshape(true, (true.size()[0],true.size()[1],17,2))\n",
    "    \n",
    "    displacement=torch.sqrt((pred[:,:,:,0]-true[:,:,:,0])**2+(pred[:,:,:,1]-true[:,:,:,1])**2)\n",
    "    ade = torch.mean(torch.mean(displacement,dim=1))\n",
    "\n",
    "    return ade\n",
    "\n",
    "\n",
    "def FDE_c(pred, true):\n",
    "    pred = torch.reshape(pred, (pred.size()[0],pred.size()[1],17,2))\n",
    "    true = torch.reshape(true, (true.size()[0],true.size()[1],17,2))\n",
    "    \n",
    "    displacement=torch.sqrt((pred[:,-1,:,0]-true[:,-1,:,0])**2+(pred[:,-1,:,1]-true[:,-1,:,1])**2)\n",
    "\n",
    "    fde = torch.mean(torch.mean(displacement,dim=1))\n",
    "    \n",
    "    return fde\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=15, \n",
    "                                                 threshold = 1e-8, verbose=True)\n",
    "print('='*100)\n",
    "print('Training ...')\n",
    "alpha=0.3\n",
    "\n",
    "for epoch in range(args.n_epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    avg_epoch_train_s_loss = 0\n",
    "    avg_epoch_val_s_loss   = 0\n",
    "    avg_epoch_train_p_loss   = 0\n",
    "    avg_epoch_val_p_loss     = 0 \n",
    "    avg_epoch_train_g_loss   = 0\n",
    "    avg_epoch_val_g_loss     = 0 \n",
    "    ade  = 0\n",
    "    fde  = 0\n",
    "    ade_train  = 0\n",
    "    fde_train  = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for idx, (obs_s, target_s, obs_pose, target_pose) in enumerate(train_loader):\n",
    "        counter += 1        \n",
    "        \n",
    "\n",
    "        \n",
    "        obs_s    = obs_s.to(device='cuda')\n",
    "        target_s = target_s.to(device='cuda')\n",
    "        obs_pose    = obs_pose.to(device='cuda')\n",
    "        target_pose = target_pose.to(device='cuda')\n",
    "#         obs_pose_global = obs_pose_global.to(device='cuda')\n",
    "#         target_pose_global = target_pose_global.to(device='cuda')\n",
    "#         obs_s_g  = obs_s_g.to(device='cuda')\n",
    "#         target_s_g = target_s_g.to(device='cuda')\n",
    "#         target = target.to(device='cuda')\n",
    "        \n",
    "#         pose_inp=(obs_pose.reshape(obs_pose.shape[0],obs_pose.shape[1],17,2)+ obs_pose_global.reshape(obs_pose.shape[0],obs_pose.shape[1],1,2)).reshape(obs_pose.shape[0],obs_pose.shape[1],34)\n",
    "#         vel_inp=(obs_s.reshape(obs_s.shape[0],obs_s.shape[1],17,2)+ obs_s_g.reshape(obs_s.shape[0],obs_s.shape[1],1,2)).reshape(obs_s.shape[0],obs_s.shape[1],34)\n",
    "        \n",
    "#         print(pose_inp.size())\n",
    "#         print(vel_inp.size())\n",
    "        \n",
    "        net.zero_grad()\n",
    "    \n",
    "#         (speed_preds,global_preds) = net(pose=obs_pose, vel=obs_s, pose_glob=obs_pose_global, vel_glob=obs_s_g)\n",
    "        (preds_p,) = net(pose=obs_pose, vel=obs_s )\n",
    "#         print(preds_p.size())\n",
    "\n",
    "#         speed_loss  = mse(speed_preds, target_s)\n",
    "#         global_loss =  mse(global_preds, target_s_g)\n",
    "#         speed_loss  = l1e(speed_preds, target_s)\n",
    "#         global_loss =  l1e(global_preds, target_s_g)\n",
    "        \n",
    "#         loss = (1-alpha)*speed_loss + alpha*global_loss\n",
    "        loss=mse(preds_p,target_pose)\n",
    "        loss.backward()\n",
    "    \n",
    "       \n",
    "    \n",
    "        ade_train += float(ADE_c(preds_p, target_pose))\n",
    "        fde_train += float(FDE_c(preds_p, target_pose))\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "#         avg_epoch_train_s_loss += float(speed_loss)\n",
    "#         avg_epoch_train_g_loss += float(global_loss)\n",
    "        \n",
    "    avg_epoch_train_s_loss /= counter\n",
    "    avg_epoch_train_g_loss /= counter\n",
    "    train_s_scores.append(avg_epoch_train_s_loss)\n",
    "    train_g_scores.append(avg_epoch_train_g_loss)\n",
    "    ade_train  /= counter\n",
    "    fde_train  /= counter  \n",
    "    counter=0\n",
    "\n",
    "    for idx, (obs_s, target_s, obs_pose, target_pose) in enumerate(val_loader):\n",
    "        counter+=1\n",
    "        obs_s    = obs_s.to(device='cuda')\n",
    "        target_s = target_s.to(device='cuda')\n",
    "        obs_pose    = obs_pose.to(device='cuda')\n",
    "        target_pose = target_pose.to(device='cuda')\n",
    "#         obs_pose_global = obs_pose_global.to(device='cuda')\n",
    "#         target_pose_global = target_pose_global.to(device='cuda')\n",
    "#         obs_s_g  = obs_s_g.to(device='cuda')\n",
    "#         target_s_g = target_s_g.to(device='cuda')\n",
    "#         target = target.to(device='cuda')\n",
    "        \n",
    "#         print(obs_pose[0,0])\n",
    "        \n",
    "#         pose_inp=(obs_pose.reshape(obs_pose.shape[0],obs_pose.shape[1],17,2)+ obs_pose_global.reshape(obs_pose.shape[0],obs_pose.shape[1],1,2)).reshape(obs_pose.shape[0],obs_pose.shape[1],34)\n",
    "#         vel_inp=(obs_s.reshape(obs_s.shape[0],obs_s.shape[1],17,2)+ obs_s_g.reshape(obs_s.shape[0],obs_s.shape[1],1,2)).reshape(obs_s.shape[0],obs_s.shape[1],34)\n",
    "        \n",
    "       \n",
    "        \n",
    "        with torch.no_grad():\n",
    "#             (speed_preds,global_preds) = net(pose=obs_pose, vel=obs_s, pose_glob=obs_pose_global, vel_glob=obs_s_g)\n",
    "\n",
    "#             speed_loss  = mse(speed_preds, target_s)\n",
    "#             global_loss =  mse(global_preds, target_s_g)\n",
    "#             loss = (1-alpha)*speed_loss + alpha*global_loss\n",
    "#             avg_epoch_val_s_loss += float(speed_loss)\n",
    "#             avg_epoch_val_g_loss += float(global_loss)\n",
    "            \n",
    "#             preds_p = speed2pos_glob(speed_preds, global_preds, obs_pose, obs_pose_global) \n",
    "            \n",
    "            (preds_p,) = net(pose=obs_pose, vel=obs_s)\n",
    "\n",
    "            loss=mse(preds_p,target_pose)\n",
    "            \n",
    "            ade += float(ADE_c(preds_p, target_pose))\n",
    "            fde += float(FDE_c(preds_p, target_pose))\n",
    "\n",
    "        \n",
    "    avg_epoch_val_s_loss /= counter\n",
    "    avg_epoch_val_g_loss /= counter\n",
    "    val_s_scores.append(avg_epoch_val_s_loss)\n",
    "    val_g_scores.append(avg_epoch_val_g_loss)\n",
    "    \n",
    "    ade  /= counter\n",
    "    fde  /= counter     \n",
    "    \n",
    "    scheduler.step(loss)\n",
    "    \n",
    "     \n",
    "    print('e:', epoch, '| ts: %.4f'% avg_epoch_train_s_loss, '| tg: %.4f'% avg_epoch_train_g_loss, '| vs: %.4f'% avg_epoch_val_s_loss, '| vg: %.4f'% avg_epoch_val_g_loss, '| ade_train: %.4f'% ade_train, '| ade_val: %.4f'% ade, '| fde_train: %.4f'% fde_train,'| fde_val: %.4f'% fde)\n",
    "#           ,'| t:%.4f'%(time.time()-start))\n",
    "\n",
    "\n",
    "print('='*100) \n",
    "# print('Saving ...')\n",
    "# torch.save(net.state_dict(), args.model_path)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_out=np.delete(array_of_seq, list(range(2, array_of_seq.shape[3], 3)), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "applicable-kruger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bigbo\\Desktop\\College\\Project\\Sc-sfmlearner\n"
     ]
    }
   ],
   "source": [
    "%cd Sc-sfmlearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "appropriate-aquatic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 592/16819 [00:00<00:02, 5897.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16819 files to test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 16819/16819 [00:02<00:00, 6670.96it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from imageio import imread, imsave\n",
    "from skimage.transform import resize as imresize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "\n",
    "from models import DispResNet\n",
    "from utils2 import tensor2array\n",
    "import glob\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "img_height=256\n",
    "img_width=832\n",
    "img_exts=['png', 'jpg', 'bmp']\n",
    "\n",
    "resnet_layers=18\n",
    "output_dir='results/'\n",
    "pretrained='checkpoints/resnet18_depth_256/dispnet_model_best.pth.tar'\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    # if not(args.output_disp or args.output_depth):\n",
    "    #     print('You must at least output one value !')\n",
    "    #     return\n",
    "\n",
    "    disp_net = DispResNet(resnet_layers, False).to(device)\n",
    "    weights = torch.load(pretrained)\n",
    "    disp_net.load_state_dict(weights['state_dict'])\n",
    "    disp_net.eval()\n",
    "\n",
    "#     dataset_dir = Path(dataset_dir)\n",
    "#     output_dir = Path(output_dir)\n",
    "#     output_dir.mkdir()\n",
    "\n",
    "#     test_files = sum([dataset_dir.files('*.{}'.format(ext)) for ext in img_exts], [])\n",
    "    test_files=glob.glob('./../frames/*/*.png')\n",
    "    \n",
    "\n",
    "    print('{} files to test'.format(len(test_files)))\n",
    "\n",
    "    for file in tqdm(test_files):\n",
    "#         print(file)\n",
    "        dst='results'+file.replace('./../frames','').replace('.png','')\n",
    "#         print(dst)\n",
    "#         break\n",
    "        if not os.path.exists(dst+'_disp.png'):\n",
    "#         print(dst)\n",
    "            os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "    #         print(file)\n",
    "\n",
    "            img = imread(file).astype(np.float32)\n",
    "\n",
    "            h, w, _ = img.shape\n",
    "\n",
    "            img = imresize(img, (img_height, img_width)).astype(np.float32)\n",
    "\n",
    "    #         fig = plt.figure(figsize=(15, 15))\n",
    "    #         a = fig.add_subplot(1, 3, 1)\n",
    "    #         imgplot = plt.imshow(img.astype(np.uint8))\n",
    "\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "            tensor_img = torch.from_numpy(img).unsqueeze(0)\n",
    "            tensor_img = ((tensor_img/255 - 0.45)/0.225).to(device)\n",
    "\n",
    "            output = disp_net(tensor_img)[0]\n",
    "\n",
    "\n",
    "            disp = (255*tensor2array(output, max_value=None, colormap='bone')).astype(np.uint8)\n",
    "\n",
    "\n",
    "            depth = 1/output\n",
    "            depth = (255*tensor2array(depth, max_value=1, colormap='magma')).astype(np.uint8)\n",
    "\n",
    "    #         a = fig.add_subplot(1, 3, 2)\n",
    "    #         imgplot = plt.imshow(np.transpose(disp,(1,2,0)))\n",
    "    #         a = fig.add_subplot(1, 3, 3)\n",
    "    #         imgplot = plt.imshow(np.transpose(depth,(1,2,0)))\n",
    "\n",
    "\n",
    "\n",
    "            imsave(dst+'_disp.png', np.transpose(disp, (1, 2, 0)))\n",
    "            imsave(dst+'_depth.png', np.transpose(depth, (1, 2, 0)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-shaft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "whole-leadership",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4de030339887>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mpose_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mimage_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0moutput_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "from inverse_warp import pose_vec2mat\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from inverse_warp import *\n",
    "import models\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "sequence='test'\n",
    "pretrained_posenet='./checkpoints/resnet50_pose_256/exp_pose_model_best.pth.tar'\n",
    "def load_tensor_image(filename):\n",
    "    img = imread(filename).astype(np.float32)\n",
    "    h, w, _ = img.shape\n",
    "    # if (not args.no_resize) and (h != img_height or w != img_width):\n",
    "    img = imresize(img, (img_height, img_width)).astype(np.float32)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    tensor_img = ((torch.from_numpy(img).unsqueeze(0)/255-0.45)/0.225).to(device)\n",
    "    return tensor_img\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    weights_pose = torch.load(pretrained_posenet)\n",
    "    pose_net = models.PoseResNet().to(device)\n",
    "    pose_net.load_state_dict(weights_pose['state_dict'], strict=False)\n",
    "    pose_net.eval()\n",
    "\n",
    "    image_dir = Path(dataset_dir)\n",
    "    output_dir = Path('./')\n",
    "    output_dir.makedirs_p()\n",
    "\n",
    "    test_files = sum([image_dir.files('*.{}'.format(ext)) for ext in img_exts], [])\n",
    "    test_files.sort()\n",
    "\n",
    "    print('{} files to test'.format(len(test_files)))\n",
    "\n",
    "    global_pose = np.eye(4)\n",
    "    poses = [global_pose[0:3, :].reshape(1, 12)]\n",
    "\n",
    "    n = len(test_files)\n",
    "    tensor_img1 = load_tensor_image(test_files[0])\n",
    "\n",
    "    for iter in tqdm(range(n - 1)):\n",
    "\n",
    "        tensor_img2 = load_tensor_image(test_files[iter+1])\n",
    "\n",
    "        pose = pose_net(tensor_img1, tensor_img2)\n",
    "\n",
    "        pose_mat = pose_vec2mat(pose).squeeze(0).cpu().numpy()\n",
    "        pose_mat = np.vstack([pose_mat, np.array([0, 0, 0, 1])])\n",
    "        global_pose = global_pose @  np.linalg.inv(pose_mat)\n",
    "\n",
    "        poses.append(global_pose[0:3, :].reshape(1, 12))\n",
    "\n",
    "        # update\n",
    "        tensor_img1 = tensor_img2\n",
    "\n",
    "    poses = np.concatenate(poses, axis=0)\n",
    "    filename = Path(output_dir + sequence + \".txt\")\n",
    "    np.savetxt(filename, poses, delimiter=' ', fmt='%1.8e')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02a4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49da5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fd296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
